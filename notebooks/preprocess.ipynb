{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f54iGu-q_qPf"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "#### This will create two numpy files you can upload to the drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD8KoZOBuXXG"
      },
      "source": [
        "## Import Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "D0vBMyRjuVT7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import csv\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "from PIL import Image\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyiMbaNl3dpa"
      },
      "source": [
        "## Image Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Om1SKTC13il6"
      },
      "outputs": [],
      "source": [
        "def preprocess(image_path):\n",
        "  # Scale down from 640 x 480 pixels to 6x smaller.\n",
        "  target_image_size = (80, 60)\n",
        "\n",
        "  # Get image and resize.\n",
        "  PIL_image = Image.open(image_path)\n",
        "  PIL_image_resized = PIL_image.resize(target_image_size, resample=Image.LANCZOS)\n",
        "\n",
        "  # Convert to NumPy array and normalize\n",
        "  image_arr = np.array(PIL_image_resized)\n",
        "  normalized_arr = image_arr / 255.0\n",
        "\n",
        "  return normalized_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qxNj_Ab7avi"
      },
      "source": [
        "## Edit the data_folder_dir below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MsvJFjYP9fhR"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Edit this directory accordingly\n",
        "data_folder_dir = \"../data/raw_data\"\n",
        "\n",
        "\n",
        "# Use glob to find every image jpg and every label.csv\n",
        "glob_image_pattern = os.path.join(data_folder_dir, 'trial_*/images/*.jpg')\n",
        "glob_label_pattern = os.path.join(data_folder_dir, 'trial_*/labels.csv')\n",
        "\n",
        "image_paths = glob.glob(glob_image_pattern)\n",
        "label_paths = glob.glob(glob_label_pattern)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SAEFbFih6GW2"
      },
      "outputs": [],
      "source": [
        "# Take 40% of the original dataset\n",
        "sample_size = int(len(image_paths) * 0.4)\n",
        "image_paths_sample = random.sample(image_paths, sample_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rPcxrOWrEd52"
      },
      "outputs": [],
      "source": [
        "# Get every label into a dictionary\n",
        "labels_dict = {}\n",
        "\n",
        "for label_path in label_paths:\n",
        "  # open the label file\n",
        "  with open(label_path, mode='r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    header = next(reader)\n",
        "\n",
        "    for row in reader:\n",
        "      timestamp = row[0]\n",
        "      throttle_on = int(row[1])\n",
        "      steering_command = float(row[2])\n",
        "\n",
        "      image_name = timestamp + '.jpg'\n",
        "\n",
        "      labels_dict[image_name] = [throttle_on, steering_command]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "ELUG-3joEhTa",
        "outputId": "23aa1f88-7617-4f77-a31d-8d6c80c8e7b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Preprocessing: 100%|██████████| 23187/23187 [04:07<00:00, 93.66it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "333892800\n",
            "46374\n"
          ]
        }
      ],
      "source": [
        "# Loop through every image and append its label.\n",
        "# Use tqdm to monitor progress\n",
        "\n",
        "for image_path in tqdm(image_paths_sample, desc=\"Preprocessing\"):\n",
        "  image_name = os.path.basename(image_path)\n",
        "\n",
        "  if image_name in labels_dict:\n",
        "    label = labels_dict[image_name]\n",
        "    image = preprocess(image_path)\n",
        "\n",
        "    images.append(image)\n",
        "    labels.append(label)\n",
        "  else:\n",
        "    print(\"Error: No matching label found.\")\n",
        "\n",
        "X_data = np.array(images)\n",
        "Y_data = np.array(labels, dtype=np.float32)\n",
        "\n",
        "print(X_data.size)\n",
        "print(Y_data.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JWeCxAbAPLva",
        "outputId": "7bd409a8-3527-46f0-892f-d6b8afe0ba37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Images data type: float64\n",
            "Labels data type: float32\n"
          ]
        }
      ],
      "source": [
        "print(\"Images data type:\", X_data.dtype)\n",
        "print(\"Labels data type:\", Y_data.dtype)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khy1iP_p_Ppx"
      },
      "source": [
        "## Edit the save_dir below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Uqjv50fq_MKW"
      },
      "outputs": [],
      "source": [
        "save_dir = \"../data/processed\"\n",
        "file_name = 'dataset.npz'\n",
        "\n",
        "save_path = os.path.join(save_dir, file_name)\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "np.savez_compressed(save_path, X_data=X_data, Y_data=Y_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gha4lzmAArgl"
      },
      "source": [
        "## References\n",
        "\n",
        "1.   https://pillow.readthedocs.io/en/stable/reference/Image.html"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0rc2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
